{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c26646f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d3e73de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"twitter_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d64e0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "nltk.download(\"twitter_samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053e97d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk                                  # Python library for NLP\n",
    "from nltk.corpus import twitter_samples      # sample Twitter dataset from NLTK\n",
    "import matplotlib.pyplot as plt              # visualization library\n",
    "import numpy as np                           # library for scientific computing and matrix operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7ed7563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloads sample twitter dataset.\n",
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0846aa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e883d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import twitter_samples\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa88346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=twitter_samples.strings(\"positive_tweets.json\")\n",
    "neg=twitter_samples.strings(\"negative_tweets.json\")\n",
    "tweets=pos+neg\n",
    "labels=np.append(np.ones((len(pos))),np.zeros((len(neg))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e61b481d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9bdb5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_tweets,test_tweets,train_lab,test_lab=train_test_split(tweets,labels,train_size=0.8,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70e7aa0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "438347c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1012"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_lab[test_lab==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffd5a24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lab=train_lab.reshape(8000,1)\n",
    "test_lab=test_lab.reshape(2000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d2b2a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    stemmer=PorterStemmer()\n",
    "    eng_stop=stopwords.words(\"english\")\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    tokenizer=TweetTokenizer(preserve_case=False,strip_handles=True,reduce_len=True)\n",
    "    tweet_tokens=tokenizer.tokenize(tweet)\n",
    "    tweets_clean=[]\n",
    "    for word in tweet_tokens:\n",
    "        if word not in eng_stop and word not in string.punctuation :\n",
    "            stem=stemmer.stem(word)\n",
    "            tweets_clean.append(stem)\n",
    "            \n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af2299aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freqs(tweets,ys):\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "    freq={}\n",
    "    for y,tweet in zip(yslist,tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            p=(word,y)\n",
    "            if p in freq:\n",
    "                freq[p]+=1\n",
    "            else:\n",
    "                freq[p]=1\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78ca0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency=freqs(tweets,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60f5f791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13067"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7128751a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['happi', 211, 25],\n",
       " ['merri', 1, 0],\n",
       " ['nice', 98, 19],\n",
       " ['good', 238, 101],\n",
       " ['bad', 18, 73],\n",
       " ['sad', 5, 123],\n",
       " ['mad', 4, 11],\n",
       " ['best', 65, 22],\n",
       " ['pretti', 20, 15],\n",
       " ['‚ù§', 29, 21],\n",
       " [':)', 3568, 2],\n",
       " [':(', 1, 4571],\n",
       " ['üòí', 1, 3],\n",
       " ['üò¨', 0, 2],\n",
       " ['üòÑ', 5, 1],\n",
       " ['üòç', 2, 1],\n",
       " ['‚ôõ', 0, 210],\n",
       " ['song', 22, 27],\n",
       " ['idea', 26, 10],\n",
       " ['power', 7, 6],\n",
       " ['play', 46, 48],\n",
       " ['magnific', 2, 0]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = ['happi', 'merri', 'nice', 'good', 'bad', 'sad', 'mad', 'best', 'pretti',\n",
    "        '‚ù§', ':)', ':(', 'üòí', 'üò¨', 'üòÑ', 'üòç', '‚ôõ',\n",
    "        'song', 'idea', 'power', 'play', 'magnific']\n",
    "data=[]\n",
    "for word in keys:\n",
    "    po=0\n",
    "    ne=0\n",
    "    if (word,1) in frequency:\n",
    "        po=frequency[(word,1)]\n",
    "    if (word,0) in frequency:\n",
    "        ne=frequency[(word,0)]\n",
    "    data.append([word,po,ne])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "801c4f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_train=freqs(train_tweets,train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4c61a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11372"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d33bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "Mod=LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d2f0fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(tweet,freq):\n",
    "    v=process_tweet(tweet)\n",
    "    x=np.zeros((1,3))\n",
    "    x[0,0]=1#bias term\n",
    "    for word in v:\n",
    "        if (word,1) in freq:\n",
    "            x[0,1]+=freq[(word,1)]\n",
    "        if (word,0) in freq:\n",
    "            x[0,2]+=freq[(word,0)]\n",
    "            \n",
    "    return x\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb5e8f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.zeros((len(train_tweets),3))\n",
    "for i in range(len(train_tweets)):\n",
    "    x_train[i,:]=features(train_tweets[i],freq_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e033444",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train_lab\n",
    "y_train=y_train.reshape(8000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20d14b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mod.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cc808f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=Mod.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "363c307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81ddb796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.990125\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_train,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3abf9673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3948   64]\n",
      " [  15 3973]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f67d22a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_test=freqs(test_tweets,test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96bd4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.zeros((len(test_tweets),3))\n",
    "for i in range(len(test_tweets)):\n",
    "    x_test[i,:]=features(test_tweets[i],freq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "451fdb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=test_lab\n",
    "y_test.shape\n",
    "y_test=y_test.reshape(2000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72f4267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=Mod.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68396dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991\n",
      "[[ 970   18]\n",
      " [   0 1012]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99       988\n",
      "         1.0       0.98      1.00      0.99      1012\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y))\n",
    "print(confusion_matrix(y_test,y))\n",
    "print(classification_report(y_test,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a723e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dcfef8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d45f8911",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MultinomialNB()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred=model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4215b78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9945\n",
      "[[ 982    6]\n",
      " [   5 1007]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99       988\n",
      "         1.0       0.99      1.00      0.99      1012\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "27c08eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet=\"The movie is bad\"\n",
    "#ys=np.ones((1,))\n",
    "#f=freqs(tweet,ys)\n",
    "x_st=np.zeros((1,3))\n",
    "x_st[0,:]=features(tweet,freq_train)\n",
    "y=model.predict(x_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "28aaa032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f16d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
